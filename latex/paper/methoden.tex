\section*{Methoden}
\label{sec:Methoden}

Um die Hypothese zu überprüfen, ob und wie stark die Ergebnisse der Spotify MIR Algorithmen mit den subjektiven Bewertungen durch Probanden korrelieren, wird ein Datensatz von Probanden bewerteter Musikstücke mit den von Spotify erzeugen Audio Features der selben Musikstücke verglichen.
Mit Hilfe statistischer Methoden wird überprüft wie stark die beiden Datensätze korrelieren.
Bei dieser Studie handelt es sich um eine Zweitverwertung des Datensatzes einer anderen Studie, daher mussten die Daten zunächst für diese Studie neu strukturiert und angepasst werden.
Der verwendete Datensatz stammt aus einer Studie, in der die Probanden angeben sollten welche 10 Songs sie mit auf eine einsame Insel nehmen würden. [ PAPER LINK ]
Anschließend mussten sie zu den von ihnen gewählten Songs folgenden 13 verschiedene Attribute bewerten: Anspruchsvoll, Einfach, Emotional, Entspannend, Erregend, Fröhlich, Intellektuell, Intensiv, Komplex, Sanft, Tanzbar, Traurig und Warm.

Einige der Variablen, wie Fröhlich und Traurig oder Warm und Sanft, stehen augenscheinlich in Beziehung zueinander oder beschreiben eine ähnliche subjektive Empfindung.
Daher liegt die Vermutung nahe, dass eine Datenreduktion der Attribute möglich ist.
Mit Hilfe einer Faktorenanalyse soll so aus den 13 Attributen, die von den Probanden bewertet wurden, einige wenige Faktoren werden.
Dazu wurde eine Hauptkomponentenfaktorenanalyse mit orthogonaler Achsenrotation (Varimax Verfahren) verwendet.
Um die Korrelation zwischen den Spotify Audio Features und den reduzierten Faktoren zu untersuchen wurde anschließend eine multiple schrittweise Regression durchgeführt.
Die reduzierten Faktoren wurden dabei als abhängige Variable verwendet und die Attribute des Spotify Algorithmus als unabhängige Variablen.



\section*{Datenaufbereitung}
\label{sec:Datenaufbereitung}


Der "`Insel"' Datensatz enthielt 45 Datenpunkte in denen sich je ein Proband mit seinen 10 Songs und deren Bewertungen befindet.
Ein Problem, das sofort ins Auge fällt, ist, dass der Datensatz schwer maschinenlesbar ist. 
Zum Beispiel sind die Songtitel und der Interpret beliebig vermischt und folgten keinem klaren Schema.
Um eine Analyse der einzelnen Songs zu ermöglichen, mussten zunächst mit Hilfe eines Python Skripts aus dem bestehenden Datensatz die einzelnen Songs und deren Bewertungen extrahieren werden.
Anschließend wurden die Daten zu insgesamt 450 neuen Datenpunkten zusammengefasst, die jeweils einen Song und seine Bewertungen enthalten.
Zusätzlich wurde die Daten aus dem veralteten CSV Format in das deutlich einfacher maschinell lesbare JSON Format konvertiert.

Um die Spotify Audio Features für einen Song zu ermitteln muss der Spotify Programmierschnittstelle (API) die dem Song entsprechende Spotify ID übergeben werden.
Diese muss zunächst für jeden Song ermittelt werden.
Da die Songtitel und Interpreten maschinell nicht einfach und klar voneinander trennbar waren, wurde die Spotify Suchfunktion verwendet.
Dieser kann eine gemischte Zeichenkette mit Titel und Interpret übergeben werden.
Sie liefert daraufhin Informationen über die Treffer der gefundenen Songs in der Spotify Datenbank mitsamt der Spotify IDs.
Wir haben die ID des ersten gefunden Treffers zu dem entsprechenden Datenpunkt des bisherigen Datensatzes hinzugefügt.
Insgesamt 50 der Songs konnten entweder auf Grund der vermischten Sucheingabe oder weil sie nicht in der Spotify Datenbank vorhanden sind nicht gefunden werden.
\footnote{Der Zugriff erfolgte am 23.2.2017 gegen 16:00 Uhr.}
Auch dieser Schritt wurde mit einem Python Script automatisiert durchgeführt.
Dafür wurde die Spotipy \footnote{Spotipy Programmbibliothek: \url{https://github.com/plamere/spotipy}} Python Bibliothek verwendet, welche einen einfachen Zugriff auf die Spotify Web Schnittstellen ermöglicht.
Nach diesem Schritt enthielt der neuer Datensatz 400 Songs mit den Probandenbewertungen und der Spotify ID.

Bei der Durchsicht des Datensatzes fiel auf, dass es sich bei einige der von Spotify gefunden Ergebnisse um völlig andere Songs handelte.
Teilweise wurden auch Instrumental Versionen oder Cover Versionen der Songs gefunden.
Stichproben ergaben das die Original Versionen dieser Songs sich nicht in der Spotify Datenbank befinden.
Aus diesem Grund wurde im Anschluss eine Datenvalidierung durchgeführt.
Dabei wurde ein einfacher Stringvergleich zwischen dem Originaltitel des "`10 Songs für die einsame Insel"' Datensatz und einer Kombination aus dem von Spotify gefunden Titel und Interpreten durchgeführt.
Eine Ähnlichkeit der Zeichenketten von 60\% führte zu einem guten Kompromiss zwischen Genauigkeit und Freiheitsgrad.
Dadurch wurden aus dem Datensatz weitere 49 Einträge entfernt, was zu einer Gesamtanzahl von 351 Datenpunkten führte.

Als nächsten Schritt wurde mit Hilfe der Spotipy Bibliothek der Spotify Audio Feature Web API die ermittelten Spotify IDs übergeben.
Dafür muss man sich zunächst bei Spotify als Developer anmelden, um eine Autorisierung zu erhalten mit der man auf die Spotify Audio Feature Web API zugreifen kann.
Für jede angefragte ID liefert die Spotify Audio Feature Web API ein JSON Objekt\,\footnote{Dokumentation: \url{https://developer.spotify.com/web-api/get-audio-features/}} zurück.
Aus diesem haben wir die für diese Studie relevanten Audio Features extrahiert und in den entsprechenden Eintrag unseres Datensatzes eingefügt.
\footnote{Der Zugriff erfolgte am 23.2.2017 gegen 16:15 Uhr.}
Dieser Vorgang wurde entsprechend für alle 351 Datenpunkte durchgeführt.

Von den insgesamt 13 von Spotify zur Verfügung gestellten Audio Feature Attributen nur 8 verwendet.
Da die Bewertungen der Umfrage subjektiven Einschätzungen entsprechen, wurden die Attribute, welche die Struktur eines Musikstücks beschreiben, nicht in die statistische Analyse mit einbezogen.
Zu diesen Attributen gehören die Länge des Songs ("`duration\_ms"'),  die Taktangabe ("`time\_signature"') sowie die Tonklasse ("`key"').
Außerdem wird das Audio Feature "`mode"' (Tongeschlecht) nicht berücksichtigt, da es sich um eine dichotome Variable handelt, welches sich für das verwendete statistische Verfahren nicht eignet.
Die verwendeten Spotify Audio Features sind im folgenden kurz beschrieben:

\begin{description}
    \item[acousticness]
        Wie wahrscheinlich handelt es sich um einen Akustiksong.
    \item[danceability]
        Eignet sich ein Song zum Tanzen?
        Wird aus verschiedenen musikalischen Elementen wie Tempo, Rhythmusstabilität, Beatstärke oder Regelmäßigkeit ermittelt.
    \item[energy]
        Beschreibt die gefühlte Wahrnehmung von Intensität und Aktivität.
        Deathmetal hat beispielsweise eine hohe Energie, ein Bach Choral eine niedrige. Der Wert setzt sich unter anderem aus der Dynamik, der wahrgenommenen Lautstärke, der Klangfarbe, den Einsätzen und der generellen Entropie zusammen.
    \item[instrumentalness]
        Vorhersage darüber ob Gesang in einem Song enthalten ist.
    \item[liveness]
        Ermittelt die Anwesenheit eines Publikums beziehungsweise ob ein Song in einer Livesituation aufgenommen wurde.
    \item[loudness]
        Gemittelte Lautstärke des Songs in Dezibel.
    \item[speechiness]
        Wie viel wird innerhalb eines Songs gesprochen?
        Unterscheidet fließend zwischen Podcasts oder Hörbücher, Musik mit hohem Anteil an Sprache (wie zum Beispiel Rap) und Musik mit geringem bis gar keinem Sprachanteil.
    \item[tempo]
        Anzahl der Beats per Minute (Bpm).
    \item[valence]
        Maß für die musikalische Fröhlichkeit bzw. Traurigkeit eines Songs.
        Fließender Übergang von fröhlich oder heiter nach traurig oder deprimierend.
\end{description}

Da die weitere statistische Auswertung des Datensatzes in der SPSS Software geschah mussten die Daten anschließend vom JSON in das CSV Format konvertiert werden, da dieses das einzige Format ist das SPSS akzeptiert.

Der gesamte Code, der für die Aufbereitung der Daten geschrieben wurde, ist unter einer Open Source Lizenz auf GitHub.com veröffentlicht \footnote{Code Repository:\hfill \url{https://github.com/Bendrien/SpotifyMIR-Evaluation/tree/master/python}}.

